{
    "tokenizer_class":"tokenizer_modules.turkish_morphological_tokenizer.TurkishMorphologicalTokenizer",
    "params":{
        "vocab_size":32000,
        "min_freq": 0,
        "input_dir": "data/",
        "input_file_pattern": "test.txt",
        "token_affix": "##",
        "special_tokens": {
            "[PAD]": 0,
            "[UNK]": 1,
            "[CLS]": 2,
            "[SEP]": 3,
            "[MASK]": 4
        },
        "zemberek_path": "data/zemberek-full.jar",
        "suffixes": {
            "root_only": false,
            "combined": false,
            "last_only": false
        },
        "model": {
            "path": "outputs/tr_seperate_suffix_32k.dat",
            "overwrite": true
        }
    }
}
